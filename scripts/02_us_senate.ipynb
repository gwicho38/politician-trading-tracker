{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# US Senate - Financial Disclosure Ingestion\n",
    "\n",
    "**Data Source:** https://efdsearch.senate.gov/search/\n",
    "\n",
    "## CLI Commands\n",
    "```bash\n",
    "mcli run us-senate run       # Run full ingestion\n",
    "mcli run us-senate status    # Check ingestion status\n",
    "mcli run us-senate list      # List downloaded disclosures\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import wraps\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import click\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from politician_trading.config import ScrapingConfig, WorkflowConfig\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "click-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "@click.group(name=\"us-senate\")\n",
    "def us_senate():\n",
    "    \"\"\"US Senate financial disclosure ingestion.\"\"\"\n",
    "    pass\n",
    "\n",
    "def click_async(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        return asyncio.run(f(*args, **kwargs))\n",
    "    return wrapper\n",
    "\n",
    "config = WorkflowConfig.default()\n",
    "scraping_config = config.scraping\n",
    "OUTPUT_DIR = project_root / 'data' / 'raw' / 'us_senate'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scraper",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_senate_disclosures(config: ScrapingConfig) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Scrape Senate EFD database.\"\"\"\n",
    "    base_url = \"https://efdsearch.senate.gov\"\n",
    "    search_url = f\"{base_url}/search/view/ptr/\"\n",
    "    disclosures = []\n",
    "    \n",
    "    async with aiohttp.ClientSession(\n",
    "        timeout=aiohttp.ClientTimeout(total=config.timeout),\n",
    "        headers={\"User-Agent\": config.user_agent}\n",
    "    ) as session:\n",
    "        logger.info(\"Fetching Senate PTR listing...\")\n",
    "        try:\n",
    "            async with session.get(search_url) as response:\n",
    "                if response.status != 200:\n",
    "                    logger.error(f\"Failed: {response.status}\")\n",
    "                    return []\n",
    "                html = await response.text()\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                rows = soup.select('tbody tr')\n",
    "                logger.info(f\"Found {len(rows)} rows\")\n",
    "                for row in rows[:100]:\n",
    "                    cells = row.find_all('td')\n",
    "                    if len(cells) >= 4:\n",
    "                        name = cells[0].get_text(strip=True)\n",
    "                        report_type = cells[1].get_text(strip=True) if len(cells) > 1 else ''\n",
    "                        filing_date = cells[2].get_text(strip=True) if len(cells) > 2 else ''\n",
    "                        link = row.find('a', href=True)\n",
    "                        report_url = base_url + link['href'] if link else None\n",
    "                        if name:\n",
    "                            disclosures.append({\n",
    "                                'politician_name': name,\n",
    "                                'report_type': report_type,\n",
    "                                'filing_date': filing_date,\n",
    "                                'source_url': report_url,\n",
    "                                'source': 'us_senate',\n",
    "                            })\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error: {e}\")\n",
    "    return disclosures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "@us_senate.command(name=\"run\")\n",
    "@click.option('--output', default=None, help='Output file path')\n",
    "@click_async\n",
    "async def run_ingestion(output: Optional[str]):\n",
    "    \"\"\"Run US Senate financial disclosure ingestion.\"\"\"\n",
    "    click.echo(\"Starting US Senate ingestion...\")\n",
    "    disclosures = await scrape_senate_disclosures(scraping_config)\n",
    "    \n",
    "    if not disclosures:\n",
    "        click.echo(\"No disclosures found.\", err=True)\n",
    "        return\n",
    "    \n",
    "    click.echo(f\"Scraped {len(disclosures)} records\")\n",
    "    \n",
    "    output_file = Path(output) if output else OUTPUT_DIR / f'senate_disclosures_{datetime.now().strftime(\"%Y%m%d\")}.json'\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump({\n",
    "            'metadata': {\n",
    "                'source': 'us_senate',\n",
    "                'downloaded_at': datetime.now().isoformat(),\n",
    "                'total_records': len(disclosures),\n",
    "            },\n",
    "            'disclosures': disclosures\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    click.echo(f\"Saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "status-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "@us_senate.command(name=\"status\")\n",
    "def check_status():\n",
    "    \"\"\"Check status of US Senate ingestion.\"\"\"\n",
    "    files = list(OUTPUT_DIR.glob('senate_disclosures_*.json'))\n",
    "    if files:\n",
    "        latest = max(files, key=lambda p: p.stat().st_mtime)\n",
    "        with open(latest) as f:\n",
    "            data = json.load(f)\n",
    "        metadata = data.get('metadata', {})\n",
    "        click.echo(f\"Latest: {latest.name}\")\n",
    "        click.echo(f\"Records: {metadata.get('total_records', 'Unknown')}\")\n",
    "        click.echo(f\"Downloaded: {metadata.get('downloaded_at', 'Unknown')}\")\n",
    "    else:\n",
    "        click.echo(\"No data found. Run 'mcli run us-senate run' first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "@us_senate.command(name=\"list\")\n",
    "@click.option('--limit', default=10, type=int, help='Number of records')\n",
    "def list_disclosures(limit: int):\n",
    "    \"\"\"List downloaded US Senate disclosures.\"\"\"\n",
    "    files = list(OUTPUT_DIR.glob('senate_disclosures_*.json'))\n",
    "    if not files:\n",
    "        click.echo(\"No data found.\")\n",
    "        return\n",
    "    latest = max(files, key=lambda p: p.stat().st_mtime)\n",
    "    with open(latest) as f:\n",
    "        data = json.load(f)\n",
    "    disclosures = data.get('disclosures', [])\n",
    "    click.echo(f\"Showing {min(limit, len(disclosures))} of {len(disclosures)}:\\n\")\n",
    "    for d in disclosures[:limit]:\n",
    "        click.echo(f\"  {d['politician_name']} - {d.get('report_type', 'N/A')}\")\n",
    "        click.echo(f\"    Date: {d.get('filing_date', 'N/A')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.11"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
