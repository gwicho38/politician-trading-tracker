{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Third-Party Aggregators - Financial Disclosure Ingestion\n",
    "\n",
    "**Data Sources:** QuiverQuant, ProPublica, StockNear\n",
    "\n",
    "## CLI Commands\n",
    "```bash\n",
    "mcli run third-party run            # Run all aggregators\n",
    "mcli run third-party run --quiver   # QuiverQuant only\n",
    "mcli run third-party run --propub   # ProPublica only\n",
    "mcli run third-party status         # Check status\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import wraps\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import click\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from politician_trading.config import WorkflowConfig\n",
    "from politician_trading.scrapers.scrapers import QuiverQuantScraper\n",
    "from politician_trading.scrapers.scrapers_third_party import ThirdPartyDataFetcher\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "click-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "@click.group(name=\"third-party\")\n",
    "def third_party():\n",
    "    \"\"\"Third-party aggregator data ingestion.\"\"\"\n",
    "    pass\n",
    "\n",
    "def click_async(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        return asyncio.run(f(*args, **kwargs))\n",
    "    return wrapper\n",
    "\n",
    "config = WorkflowConfig.default()\n",
    "scraping_config = config.scraping\n",
    "OUTPUT_DIR = project_root / 'data' / 'raw' / 'third_party'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "@third_party.command(name=\"run\")\n",
    "@click.option('--quiver', is_flag=True, help='Scrape QuiverQuant only')\n",
    "@click.option('--propub', is_flag=True, help='Scrape ProPublica only')\n",
    "@click.option('--output', default=None, help='Output file path')\n",
    "@click_async\n",
    "async def run_ingestion(quiver: bool, propub: bool, output: Optional[str]):\n",
    "    \"\"\"Run third-party aggregator ingestion.\"\"\"\n",
    "    all_disclosures = []\n",
    "    by_source = {}\n",
    "    \n",
    "    # If no specific flag, run all\n",
    "    run_all = not quiver and not propub\n",
    "    \n",
    "    # QuiverQuant\n",
    "    if quiver or run_all:\n",
    "        click.echo(\"Scraping QuiverQuant...\")\n",
    "        scraper = QuiverQuantScraper(scraping_config)\n",
    "        async with scraper:\n",
    "            trades = await scraper.scrape_congress_trades()\n",
    "        click.echo(f\"  QuiverQuant: {len(trades)} trades\")\n",
    "        for t in trades:\n",
    "            all_disclosures.append({'source': 'quiverquant', **t})\n",
    "        by_source['quiverquant'] = len(trades)\n",
    "    \n",
    "    # ProPublica\n",
    "    if propub or run_all:\n",
    "        api_key = os.getenv('PROPUBLICA_API_KEY')\n",
    "        if api_key:\n",
    "            click.echo(\"Fetching ProPublica...\")\n",
    "            fetcher = ThirdPartyDataFetcher(propublica_api_key=api_key)\n",
    "            data = fetcher.fetch_from_propublica()\n",
    "            count = len(data.get('disclosures', []))\n",
    "            click.echo(f\"  ProPublica: {count} disclosures\")\n",
    "            for d in data.get('disclosures', []):\n",
    "                all_disclosures.append({'source': 'propublica', 'data': str(d)})\n",
    "            by_source['propublica'] = count\n",
    "        else:\n",
    "            click.echo(\"  ProPublica: Skipped (no API key)\")\n",
    "    \n",
    "    click.echo(f\"\\nTotal: {len(all_disclosures)} records\")\n",
    "    \n",
    "    output_file = Path(output) if output else OUTPUT_DIR / f'third_party_{datetime.now().strftime(\"%Y%m%d\")}.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump({\n",
    "            'metadata': {\n",
    "                'sources': list(by_source.keys()),\n",
    "                'downloaded_at': datetime.now().isoformat(),\n",
    "                'total_records': len(all_disclosures),\n",
    "                'by_source': by_source,\n",
    "            },\n",
    "            'disclosures': all_disclosures\n",
    "        }, f, indent=2, default=str)\n",
    "    click.echo(f\"Saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "status-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "@third_party.command(name=\"status\")\n",
    "def check_status():\n",
    "    \"\"\"Check status of third-party ingestion.\"\"\"\n",
    "    files = list(OUTPUT_DIR.glob('third_party_*.json'))\n",
    "    if files:\n",
    "        latest = max(files, key=lambda p: p.stat().st_mtime)\n",
    "        with open(latest) as f:\n",
    "            data = json.load(f)\n",
    "        metadata = data.get('metadata', {})\n",
    "        click.echo(f\"Latest: {latest.name}\")\n",
    "        click.echo(f\"Records: {metadata.get('total_records', 'Unknown')}\")\n",
    "        click.echo(f\"Sources: {metadata.get('by_source', {})}\")\n",
    "    else:\n",
    "        click.echo(\"No data found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.11"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
