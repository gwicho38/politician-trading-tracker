{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Politician Trading Data Ingestion Orchestrator\n",
    "\n",
    "Master orchestrator for all ingestion pipelines.\n",
    "\n",
    "## CLI Commands\n",
    "```bash\n",
    "mcli run ingest run                  # Run all pipelines\n",
    "mcli run ingest run --us-only        # Run US pipelines only\n",
    "mcli run ingest run --intl-only      # Run international only\n",
    "mcli run ingest status               # Check status of all pipelines\n",
    "mcli run ingest list-pipelines       # List available pipelines\n",
    "```\n",
    "\n",
    "## Pipelines\n",
    "\n",
    "### US Federal\n",
    "- `us-house` - US House of Representatives\n",
    "- `us-senate` - US Senate\n",
    "- `third-party` - QuiverQuant, ProPublica, StockNear\n",
    "\n",
    "### US States\n",
    "- `us-states` - CA, TX, NY, FL, IL, PA, MA\n",
    "\n",
    "### International\n",
    "- `uk-parliament` - UK Parliament Register of Interests\n",
    "- `eu-parliament` - EU Parliament MEP Declarations\n",
    "- `eu-states` - Germany, France, Italy, Spain, Netherlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import wraps\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import click\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from politician_trading.config import WorkflowConfig\n",
    "from politician_trading.scrapers.scrapers import CongressTradingScraper, QuiverQuantScraper, EUParliamentScraper\n",
    "from politician_trading.scrapers.scrapers_uk import run_uk_parliament_collection\n",
    "from politician_trading.scrapers.scrapers_eu import run_eu_member_states_collection\n",
    "from politician_trading.scrapers.scrapers_us_states import run_us_states_collection\n",
    "from politician_trading.scrapers.scrapers_california import run_california_collection\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "click-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "@click.group(name=\"ingest\")\n",
    "def ingest():\n",
    "    \"\"\"Master orchestrator for all politician trading data ingestion.\"\"\"\n",
    "    pass\n",
    "\n",
    "def click_async(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        return asyncio.run(f(*args, **kwargs))\n",
    "    return wrapper\n",
    "\n",
    "config = WorkflowConfig.default()\n",
    "scraping_config = config.scraping\n",
    "OUTPUT_DIR = project_root / 'data' / 'raw'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PIPELINES = {\n",
    "    'us_house': {'category': 'us_federal', 'desc': 'US House of Representatives'},\n",
    "    'us_senate': {'category': 'us_federal', 'desc': 'US Senate'},\n",
    "    'third_party': {'category': 'us_federal', 'desc': 'QuiverQuant, ProPublica'},\n",
    "    'us_states': {'category': 'us_states', 'desc': 'TX, NY, FL, IL, PA, MA'},\n",
    "    'california': {'category': 'us_states', 'desc': 'California NetFile/FPPC'},\n",
    "    'uk_parliament': {'category': 'international', 'desc': 'UK Parliament'},\n",
    "    'eu_parliament': {'category': 'international', 'desc': 'EU Parliament MEPs'},\n",
    "    'eu_member_states': {'category': 'international', 'desc': 'DE, FR, IT, ES, NL'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_single_pipeline(name: str, scraping_config) -> tuple:\n",
    "    \"\"\"Run a single pipeline and return (name, count, status).\"\"\"\n",
    "    start = datetime.now()\n",
    "    try:\n",
    "        logger.info(f\"Starting: {name}\")\n",
    "        disclosures = []\n",
    "        \n",
    "        if name == 'us_house':\n",
    "            scraper = CongressTradingScraper(scraping_config)\n",
    "            async with scraper:\n",
    "                disclosures = await scraper.scrape_house_disclosures()\n",
    "        elif name == 'us_senate':\n",
    "            scraper = CongressTradingScraper(scraping_config)\n",
    "            async with scraper:\n",
    "                disclosures = await scraper.scrape_senate_disclosures()\n",
    "        elif name == 'third_party':\n",
    "            scraper = QuiverQuantScraper(scraping_config)\n",
    "            async with scraper:\n",
    "                disclosures = await scraper.scrape_congress_trades()\n",
    "        elif name == 'us_states':\n",
    "            disclosures = await run_us_states_collection(scraping_config)\n",
    "        elif name == 'california':\n",
    "            disclosures = await run_california_collection(scraping_config)\n",
    "        elif name == 'uk_parliament':\n",
    "            disclosures = await run_uk_parliament_collection(scraping_config)\n",
    "        elif name == 'eu_parliament':\n",
    "            scraper = EUParliamentScraper(scraping_config)\n",
    "            async with scraper:\n",
    "                disclosures = await scraper.scrape_mep_declarations()\n",
    "        elif name == 'eu_member_states':\n",
    "            disclosures = await run_eu_member_states_collection(scraping_config)\n",
    "        \n",
    "        duration = (datetime.now() - start).total_seconds()\n",
    "        logger.info(f\"Completed {name}: {len(disclosures)} records in {duration:.1f}s\")\n",
    "        return (name, len(disclosures), 'success', disclosures)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed {name}: {e}\")\n",
    "        return (name, 0, f'failed: {e}', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ingest.command(name=\"run\")\n",
    "@click.option('--us-only', is_flag=True, help='Run only US pipelines')\n",
    "@click.option('--intl-only', is_flag=True, help='Run only international pipelines')\n",
    "@click.option('--pipeline', default=None, help='Run specific pipeline')\n",
    "@click.option('--output', default=None, help='Output directory')\n",
    "@click_async\n",
    "async def run_ingestion(us_only: bool, intl_only: bool, pipeline: Optional[str], output: Optional[str]):\n",
    "    \"\"\"Run ingestion pipelines.\"\"\"\n",
    "    pipelines_to_run = []\n",
    "    \n",
    "    if pipeline:\n",
    "        pipeline = pipeline.lower().replace('-', '_')\n",
    "        if pipeline not in PIPELINES:\n",
    "            click.echo(f\"Unknown pipeline: {pipeline}\", err=True)\n",
    "            click.echo(f\"Available: {', '.join(PIPELINES.keys())}\")\n",
    "            return\n",
    "        pipelines_to_run = [pipeline]\n",
    "    elif us_only:\n",
    "        pipelines_to_run = [p for p, info in PIPELINES.items() if info['category'] in ('us_federal', 'us_states')]\n",
    "    elif intl_only:\n",
    "        pipelines_to_run = [p for p, info in PIPELINES.items() if info['category'] == 'international']\n",
    "    else:\n",
    "        pipelines_to_run = list(PIPELINES.keys())\n",
    "    \n",
    "    click.echo(f\"Running {len(pipelines_to_run)} pipelines...\\n\")\n",
    "    \n",
    "    results = []\n",
    "    all_disclosures = []\n",
    "    \n",
    "    for name in pipelines_to_run:\n",
    "        click.echo(f\"  [{name}] Starting...\")\n",
    "        name, count, status, disclosures = await run_single_pipeline(name, scraping_config)\n",
    "        results.append((name, count, status))\n",
    "        all_disclosures.extend(disclosures)\n",
    "        status_icon = \"OK\" if status == 'success' else \"FAIL\"\n",
    "        click.echo(f\"  [{name}] {status_icon} - {count} records\")\n",
    "    \n",
    "    # Summary\n",
    "    click.echo(\"\\n\" + \"=\"*50)\n",
    "    click.echo(\"SUMMARY\")\n",
    "    click.echo(\"=\"*50)\n",
    "    \n",
    "    total = sum(r[1] for r in results)\n",
    "    successful = sum(1 for r in results if r[2] == 'success')\n",
    "    failed = len(results) - successful\n",
    "    \n",
    "    click.echo(f\"Total records: {total}\")\n",
    "    click.echo(f\"Pipelines: {successful} success, {failed} failed\")\n",
    "    \n",
    "    # Save summary\n",
    "    out_dir = Path(output) if output else OUTPUT_DIR\n",
    "    summary_file = out_dir / f'ingestion_summary_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "    \n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump({\n",
    "            'run_timestamp': datetime.now().isoformat(),\n",
    "            'total_records': total,\n",
    "            'successful': successful,\n",
    "            'failed': failed,\n",
    "            'results': [{'pipeline': n, 'records': c, 'status': s} for n, c, s in results],\n",
    "        }, f, indent=2)\n",
    "    click.echo(f\"\\nSaved summary: {summary_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-pipelines",
   "metadata": {},
   "outputs": [],
   "source": "@ingest.command(name=\"list-pipelines\")\ndef list_pipelines():\n    \"\"\"List available ingestion pipelines.\"\"\"\n    click.echo(\"Available pipelines:\\n\")\n    \n    categories = {'us_federal': 'US Federal', 'us_states': 'US States', 'international': 'International'}\n    \n    for cat_key, cat_name in categories.items():\n        click.echo(f\"{cat_name}:\")\n        for name, info in PIPELINES.items():\n            if info['category'] == cat_key:\n                click.echo(f\"  - {name}: {info['desc']}\")\n        click.echo()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "status-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ingest.command(name=\"status\")\n",
    "def check_status():\n",
    "    \"\"\"Check status of all ingestion pipelines.\"\"\"\n",
    "    click.echo(\"Checking pipeline data status...\\n\")\n",
    "    \n",
    "    pipeline_dirs = {\n",
    "        'us_house': 'us_house',\n",
    "        'us_senate': 'us_senate',\n",
    "        'third_party': 'third_party',\n",
    "        'us_states': 'us_states',\n",
    "        'california': 'us_states',\n",
    "        'uk_parliament': 'uk_parliament',\n",
    "        'eu_parliament': 'eu_parliament',\n",
    "        'eu_member_states': 'eu_member_states',\n",
    "    }\n",
    "    \n",
    "    for pipeline, subdir in pipeline_dirs.items():\n",
    "        data_dir = OUTPUT_DIR / subdir\n",
    "        if data_dir.exists():\n",
    "            files = list(data_dir.glob('*.json'))\n",
    "            if files:\n",
    "                latest = max(files, key=lambda p: p.stat().st_mtime)\n",
    "                mtime = datetime.fromtimestamp(latest.stat().st_mtime)\n",
    "                click.echo(f\"  {pipeline}: {len(files)} files, latest: {mtime.strftime('%Y-%m-%d %H:%M')}\")\n",
    "            else:\n",
    "                click.echo(f\"  {pipeline}: No data\")\n",
    "        else:\n",
    "            click.echo(f\"  {pipeline}: No data directory\")\n",
    "    \n",
    "    # Check for summary files\n",
    "    summaries = list(OUTPUT_DIR.glob('ingestion_summary_*.json'))\n",
    "    if summaries:\n",
    "        latest = max(summaries, key=lambda p: p.stat().st_mtime)\n",
    "        with open(latest) as f:\n",
    "            data = json.load(f)\n",
    "        click.echo(f\"\\nLatest run: {data.get('run_timestamp', 'Unknown')}\")\n",
    "        click.echo(f\"Total records: {data.get('total_records', 'Unknown')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}